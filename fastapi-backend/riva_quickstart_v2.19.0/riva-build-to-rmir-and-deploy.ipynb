{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7412e9ab",
   "metadata": {},
   "source": [
    "# Riva Build Model from `.riva` to `.rmir`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41dd8037",
   "metadata": {},
   "source": [
    "## Check current path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fe1805a7-1ef2-4586-a9c9-5672993f9ca9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/trin/projects/thai-asr/fastapi-backend/riva_quickstart_v2.19.0/riva-build-deploy\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30acf2ce",
   "metadata": {},
   "source": [
    "## Assign Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7aef58b7-5c0e-45e7-8f71-b9b991017627",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed\n"
     ]
    }
   ],
   "source": [
    "# IMPORTANT: UPDATE THESE PATHS \n",
    "\n",
    "# Riva Docker\n",
    "RIVA_CONTAINER = \"nvcr.io/nvidia/riva/riva-speech:2.19.0\"\n",
    "\n",
    "# Example: \n",
    "# RIVA_CONTAINER = f\"nvcr.io/nvidia/riva/riva-speech:{__riva_version__}\"\n",
    "\n",
    "# Directory where the .riva model is stored $MODEL_LOC/*.riva\n",
    "# Folder that .riva model stored\n",
    "MODEL_LOC = \"/home/trin/projects/thai-asr/fastapi-backend/riva_quickstart_v2.19.0/converted_models\"\n",
    "\n",
    "# Name of the .riva file\n",
    "MODEL_NAME = \"conformer_th.riva\"\n",
    "\n",
    "#เพิ่ม key ที่ใช้ ตอนแปรงโมเดล จากnemo มา riva\n",
    "KEY = \"nemotoriva\"\n",
    "\n",
    "print(\"Completed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95e081cb",
   "metadata": {},
   "source": [
    "## Get Riva Docker Container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cfc78d11-5399-4e5e-b902-b1672618c37b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.19.0: Pulling from nvidia/riva/riva-speech\n",
      "Digest: sha256:294b57bb22fc1c9eb7a180ac4e548fe963b452dec747df825af343806bdee8b5\n",
      "Status: Image is up to date for nvcr.io/nvidia/riva/riva-speech:2.19.0\n",
      "nvcr.io/nvidia/riva/riva-speech:2.19.0\n"
     ]
    }
   ],
   "source": [
    "# Get the Riva Docker container\n",
    "! docker pull $RIVA_CONTAINER"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12a96764",
   "metadata": {},
   "source": [
    "## Create folder to store `.rmir` file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aea74530-be97-42a0-828f-ec1eec88e2fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "! mkdir -p $MODEL_LOC/rmir"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f8b9d48",
   "metadata": {},
   "source": [
    "## Start build `.rmir` file from `.riva`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6209e58",
   "metadata": {},
   "source": [
    "## For Streaming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1576b7a8-14a6-4e03-bf26-7e406708ac42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==========================\n",
      "=== Riva Speech Skills ===\n",
      "==========================\n",
      "\n",
      "NVIDIA Release 25.02 (build 151443007)\n",
      "\n",
      "Copyright (c) 2018-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved.\n",
      "\n",
      "Various files include modifications (c) NVIDIA CORPORATION & AFFILIATES.  All rights reserved.\n",
      "\n",
      "This container image and its contents are governed by the NVIDIA Deep Learning Container License.\n",
      "By pulling and using the container, you accept the terms and conditions of this license:\n",
      "https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license\n",
      "\n",
      "[TensorRT-LLM] TensorRT-LLM version: 0.17.0\n",
      "2025-07-29 09:59:37,548 [INFO] Packing binaries for nn: {'onnx': ('nemo.collections.asr.models.ctc_bpe_models.EncDecCTCModelBPE', 'model_graph.onnx')}\n",
      "2025-07-29 09:59:37,548 [INFO] Copying onnx:model_graph.onnx -> nn:nn-model_graph.onnx\n",
      "2025-07-29 09:59:40,206 [INFO] Packing binaries for asr_ensemble_backend: {'vocab_file': '/tmp/tmpo65s2a7a/riva_decoder_vocabulary.txt'}\n",
      "2025-07-29 09:59:40,206 [INFO] Copying vocab_file:/tmp/tmpo65s2a7a/riva_decoder_vocabulary.txt -> asr_ensemble_backend:asr_ensemble_backend-riva_decoder_vocabulary.txt\n",
      "2025-07-29 09:59:40,206 [INFO] Packing binaries for vad_nn: {}\n",
      "2025-07-29 09:59:40,211 [INFO] Saving to /data/rmir/conformer_th_streaming.rmir\n"
     ]
    }
   ],
   "source": [
    "# Syntax: riva-build <task-name> output-dir-for-rmir/model.rmir:key dir-for-riva/model.riva:key\n",
    "! docker run --rm --gpus all -v $MODEL_LOC:/data $RIVA_CONTAINER -- \\\n",
    "    riva-build speech_recognition \\\n",
    "        /data/rmir/conformer_th_streaming.rmir:$KEY \\\n",
    "        /data/$MODEL_NAME:$KEY \\\n",
    "        --name=conformer-th-streaming \\\n",
    "        --return_separate_utterances=False \\\n",
    "        --featurizer.use_utterance_norm_params=False \\\n",
    "        --featurizer.precalc_norm_time_steps=0 \\\n",
    "        --featurizer.precalc_norm_params=False \\\n",
    "        --ms_per_timestep=80 \\\n",
    "        --endpointing.start_history=200 \\\n",
    "        --nn.fp16_needs_obey_precision_pass \\\n",
    "        --endpointing.residue_blanks_at_start=-2 \\\n",
    "        --chunk_size=0.16 \\\n",
    "        --left_padding_size=1.92 \\\n",
    "        --right_padding_size=1.92 \\\n",
    "        --decoder_type=greedy \\\n",
    "        --greedy_decoder.asr_model_delay=-1 \\\n",
    "        --language_code=th-TH"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60bf7945",
   "metadata": {},
   "source": [
    "## For offline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4809b28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==========================\n",
      "=== Riva Speech Skills ===\n",
      "==========================\n",
      "\n",
      "NVIDIA Release 25.02 (build 151443007)\n",
      "\n",
      "Copyright (c) 2018-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved.\n",
      "\n",
      "Various files include modifications (c) NVIDIA CORPORATION & AFFILIATES.  All rights reserved.\n",
      "\n",
      "This container image and its contents are governed by the NVIDIA Deep Learning Container License.\n",
      "By pulling and using the container, you accept the terms and conditions of this license:\n",
      "https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license\n",
      "\n",
      "[TensorRT-LLM] TensorRT-LLM version: 0.17.0\n",
      "2025-07-28 17:33:29,978 [INFO] Packing binaries for nn: {'onnx': ('nemo.collections.asr.models.ctc_bpe_models.EncDecCTCModelBPE', 'model_graph.onnx')}\n",
      "2025-07-28 17:33:29,978 [INFO] Copying onnx:model_graph.onnx -> nn:nn-model_graph.onnx\n",
      "2025-07-28 17:33:30,192 [INFO] Packing binaries for asr_ensemble_backend: {'vocab_file': '/tmp/tmpw68fgck4/riva_decoder_vocabulary.txt'}\n",
      "2025-07-28 17:33:30,192 [INFO] Copying vocab_file:/tmp/tmpw68fgck4/riva_decoder_vocabulary.txt -> asr_ensemble_backend:asr_ensemble_backend-riva_decoder_vocabulary.txt\n",
      "2025-07-28 17:33:30,192 [INFO] Packing binaries for vad_nn: {}\n",
      "2025-07-28 17:33:30,197 [INFO] Saving to /data/rmir/conformer_th_offline.rmir\n"
     ]
    }
   ],
   "source": [
    "# Syntax: riva-build <task-name> output-dir-for-rmir/model.rmir:key dir-for-riva/model.riva:key\n",
    "! docker run --rm --gpus all -v $MODEL_LOC:/data $RIVA_CONTAINER -- \\\n",
    "    riva-build speech_recognition \\\n",
    "        /data/rmir/conformer_th_offline.rmir:$KEY \\\n",
    "        /data/$MODEL_NAME:$KEY \\\n",
    "        --offline \\\n",
    "        --name=conformer-th \\\n",
    "        --return_separate_utterances=True \\\n",
    "        --featurizer.use_utterance_norm_params=False \\\n",
    "        --featurizer.precalc_norm_time_steps=0 \\\n",
    "        --featurizer.precalc_norm_params=False \\\n",
    "        --ms_per_timestep=80 \\\n",
    "        --endpointing.start_history=200 \\\n",
    "        --nn.use_trt_fp32 \\\n",
    "        --endpointing.residue_blanks_at_start=-2 \\\n",
    "        --chunk_size=4.8 \\\n",
    "        --left_padding_size=1.6 \\\n",
    "        --right_padding_size=1.6 \\\n",
    "        --max_batch_size=16 \\\n",
    "        --featurizer.max_batch_size=512 \\\n",
    "        --featurizer.max_execution_batch_size=512 \\\n",
    "        --decoder_type=greedy \\\n",
    "        --greedy_decoder.asr_model_delay=-1 \\\n",
    "        --language_code=th-TH\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "229ec17e",
   "metadata": {},
   "source": [
    "# Riva-Deploy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b1e8788b-1781-4ba4-a592-41691abbcf4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: onnxruntime in /home/trin/anaconda3/envs/thai-asr/lib/python3.12/site-packages (1.22.1)\n",
      "Requirement already satisfied: coloredlogs in /home/trin/anaconda3/envs/thai-asr/lib/python3.12/site-packages (from onnxruntime) (15.0.1)\n",
      "Requirement already satisfied: flatbuffers in /home/trin/anaconda3/envs/thai-asr/lib/python3.12/site-packages (from onnxruntime) (25.2.10)\n",
      "Requirement already satisfied: numpy>=1.21.6 in /home/trin/anaconda3/envs/thai-asr/lib/python3.12/site-packages (from onnxruntime) (1.26.4)\n",
      "Requirement already satisfied: packaging in /home/trin/anaconda3/envs/thai-asr/lib/python3.12/site-packages (from onnxruntime) (24.2)\n",
      "Requirement already satisfied: protobuf in /home/trin/anaconda3/envs/thai-asr/lib/python3.12/site-packages (from onnxruntime) (5.29.5)\n",
      "Requirement already satisfied: sympy in /home/trin/anaconda3/envs/thai-asr/lib/python3.12/site-packages (from onnxruntime) (1.13.3)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in /home/trin/anaconda3/envs/thai-asr/lib/python3.12/site-packages (from coloredlogs->onnxruntime) (10.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/trin/anaconda3/envs/thai-asr/lib/python3.12/site-packages (from sympy->onnxruntime) (1.3.0)\n",
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: onnxruntime-gpu in /home/trin/anaconda3/envs/thai-asr/lib/python3.12/site-packages (1.22.0)\n",
      "Requirement already satisfied: coloredlogs in /home/trin/anaconda3/envs/thai-asr/lib/python3.12/site-packages (from onnxruntime-gpu) (15.0.1)\n",
      "Requirement already satisfied: flatbuffers in /home/trin/anaconda3/envs/thai-asr/lib/python3.12/site-packages (from onnxruntime-gpu) (25.2.10)\n",
      "Requirement already satisfied: numpy>=1.21.6 in /home/trin/anaconda3/envs/thai-asr/lib/python3.12/site-packages (from onnxruntime-gpu) (1.26.4)\n",
      "Requirement already satisfied: packaging in /home/trin/anaconda3/envs/thai-asr/lib/python3.12/site-packages (from onnxruntime-gpu) (24.2)\n",
      "Requirement already satisfied: protobuf in /home/trin/anaconda3/envs/thai-asr/lib/python3.12/site-packages (from onnxruntime-gpu) (5.29.5)\n",
      "Requirement already satisfied: sympy in /home/trin/anaconda3/envs/thai-asr/lib/python3.12/site-packages (from onnxruntime-gpu) (1.13.3)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in /home/trin/anaconda3/envs/thai-asr/lib/python3.12/site-packages (from coloredlogs->onnxruntime-gpu) (10.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/trin/anaconda3/envs/thai-asr/lib/python3.12/site-packages (from sympy->onnxruntime-gpu) (1.3.0)\n",
      "Completed\n"
     ]
    }
   ],
   "source": [
    "! pip install --upgrade onnxruntime\n",
    "! pip install --upgrade onnxruntime-gpu\n",
    "print(\"Completed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6146ff6",
   "metadata": {},
   "source": [
    "### With WSL Terminal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1527b95b",
   "metadata": {},
   "outputs": [],
   "source": [
    "```\n",
    "docker run --rm --gpus all -v \"/home/trin/projects/thai-asr/fastapi-backend/riva_quickstart_v2.19.0/riva-build-deploy/riva_model\":/data \"nvcr.io/nvidia/riva/riva-speech:2.19.0\" -- \\\n",
    "    riva-deploy -f  \\\n",
    "        /data/rmir/conformer_th.rmir:\"nemotoriva\" \\\n",
    "        /data/rmir/conformer_th_offline.rmir:\"nemotoriva\" \\\n",
    "        /data/models/\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8db33e03",
   "metadata": {},
   "source": [
    "### With Jupyter Lab .ipynb file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d652c48e",
   "metadata": {},
   "source": [
    "### Deploy Streaming Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d90ff90",
   "metadata": {},
   "outputs": [],
   "source": [
    "! docker run --rm --gpus all -v $MODEL_LOC:/data $RIVA_CONTAINER -- \\\n",
    "    riva-deploy -f  \\\n",
    "        /data/rmir/conformer_th_streaming.rmir:$KEY \\\n",
    "        /data/models/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23ab6f83",
   "metadata": {},
   "source": [
    "### Deploy Offline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0574a10f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==========================\n",
      "=== Riva Speech Skills ===\n",
      "==========================\n",
      "\n",
      "NVIDIA Release 25.02 (build 151443007)\n",
      "\n",
      "Copyright (c) 2018-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved.\n",
      "\n",
      "Various files include modifications (c) NVIDIA CORPORATION & AFFILIATES.  All rights reserved.\n",
      "\n",
      "This container image and its contents are governed by the NVIDIA Deep Learning Container License.\n",
      "By pulling and using the container, you accept the terms and conditions of this license:\n",
      "https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license\n",
      "\n",
      "[TensorRT-LLM] TensorRT-LLM version: 0.17.0\n",
      "2025-07-28 17:34:02,511 [INFO] Writing Riva model repository to '/data/models/'...\n",
      "2025-07-28 17:34:02,511 [INFO] The riva model repo target directory is /data/models/\n",
      "2025-07-28 17:34:06,226 [INFO] Using tensorrt with fp32\n",
      "2025-07-28 17:34:06,226 [INFO] Extract_binaries for nn -> /data/models/riva-trt-conformer-th-offline-am-streaming-offline/1\n",
      "2025-07-28 17:34:06,226 [INFO] extracting {'onnx': ('nemo.collections.asr.models.ctc_bpe_models.EncDecCTCModelBPE', 'model_graph.onnx')} -> /data/models/riva-trt-conformer-th-offline-am-streaming-offline/1\n",
      "2025-07-28 17:34:06,877 [INFO] Printing copied artifacts:\n",
      "2025-07-28 17:34:06,877 [INFO] {'onnx': '/data/models/riva-trt-conformer-th-offline-am-streaming-offline/1/model_graph.onnx'}\n",
      "2025-07-28 17:34:06,877 [INFO] Building TRT engine from ONNX file /data/models/riva-trt-conformer-th-offline-am-streaming-offline/1/model_graph.onnx\n",
      "[07/28/2025-17:34:23] [TRT] [W] ModelImporter.cpp:459: Make sure input length has Int64 binding.\n",
      "2025-07-28 17:35:03,368 [INFO] Writing engine to model repository: /data/models/riva-trt-conformer-th-offline-am-streaming-offline/1/model.plan\n",
      "2025-07-28 17:35:07,167 [INFO] Extract_binaries for asr_ensemble_backend -> /data/models/conformer-th-offline-asr-bls-ensemble/1\n",
      "2025-07-28 17:35:07,169 [INFO] extracting {'vocab_file': '/tmp/tmpw68fgck4/riva_decoder_vocabulary.txt'} -> /data/models/conformer-th-offline-asr-bls-ensemble/1\n",
      "2025-07-28 17:35:07,173 [INFO] {'vocab_file': '/data/models/conformer-th-offline-asr-bls-ensemble/1/riva_decoder_vocabulary.txt'}\n",
      "[''][W] Inference failed. You may want to try enabling partitioning to see better results. Note: Error was:\n",
      "[ONNXRuntimeError] : 2 : INVALID_ARGUMENT : Failed to load model with error: /onnxruntime_src/onnxruntime/core/graph/model.cc:180 onnxruntime::Model::Model(onnx::ModelProto&&, const PathString&, const IOnnxRuntimeOpSchemaRegistryList*, const onnxruntime::logging::Logger&, const onnxruntime::ModelOptions&) Unsupported model IR version: 10, max supported IR version: 9\n"
     ]
    }
   ],
   "source": [
    "# Syntax: riva-deploy -f dir-for-rmir/model.rmir:key output-dir-for-repository\n",
    "# Change --gpus from 0 to all\n",
    "# Change name of model.rmir\n",
    "! docker run --rm --gpus all -v $MODEL_LOC:/data $RIVA_CONTAINER -- \\\n",
    "    riva-deploy -f  \\\n",
    "        /data/rmir/conformer_th_offline.rmir:$KEY \\\n",
    "        /data/models/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thai-asr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
